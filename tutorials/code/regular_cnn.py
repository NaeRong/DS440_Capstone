# -*- coding: utf-8 -*-
"""regular_cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10GQJ2jILwNGCsfajRbkWcsCHv7csbqf9
"""

from __future__ import print_function, division
import pandas as pd
import numpy as np
import skimage
import pandas
import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
from torch.utils.data.sampler import SubsetRandomSampler
from PIL import Image
import pandas as pd
# Ignore warnings
import warnings
warnings.filterwarnings("ignore")

class FloodTinyDataset(Dataset):

    def __init__(self, csv_file, label_csv, transform = None):
       
        self.flood_tiny_metadata = pd.read_csv(csv_file)
        self.flood_tiny_label = pd.read_csv(label_csv)
        self.flood_tiny_data = pd.merge(self.flood_tiny_metadata, 
                                        self.flood_tiny_label,
                                       on="s3_path")
        ''' Change self.root_dir to load images '''
        self.root_dir = f"/content/drive/My Drive/ladi/Images/flood_tiny/"
        self.transform = transform

    def __len__(self):
        return len(self.flood_tiny_metadata)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        pos = self.flood_tiny_metadata.iloc[idx, 9].rfind('/')+1
        img_name = os.path.join(self.root_dir, self.flood_tiny_metadata.iloc[idx, 9][pos:])    
        #img_name = self.flood_tiny_metadata.iloc[idx, 10]
        
        image = Image.fromarray(io.imread(img_name))
        uuid = self.flood_tiny_data.iloc[idx, 1]
        timestamp = self.flood_tiny_data.iloc[idx, 2]
        gps_lat = self.flood_tiny_data.iloc[idx, 3]
        gps_lon = self.flood_tiny_data.iloc[idx, 4]
        gps_alt = self.flood_tiny_data.iloc[idx, 5]
        file_size = self.flood_tiny_data.iloc[idx, 6]
        width = self.flood_tiny_data.iloc[idx, 7]
        height = self.flood_tiny_data.iloc[idx, 8]
        ### Labels should be numerical, not bool for training ###
        if self.flood_tiny_data.iloc[idx, -1] == True:
            label = 1
        else:
            label = 0
        
        if self.transform:
            image = self.transform(image)

        sample = {'image': image, 'image_name': img_name, 'damage:flood/water': label, 'uuid': uuid, 'timestamp': timestamp, 'gps_lat': gps_lat, 'gps_lon': gps_lon, 'gps_alt': gps_alt, 'orig_file_size': file_size, 'orig_width': width, 'orig_height': height}

        return sample

def show_image(image):
    plt.imshow(image)
    # pause a bit so that plots are updated
    plt.pause(0.01)

csv_file = './flood_tiny_metadata.csv'
label_csv = './flood_tiny_label.csv'

flood_tiny_dataset = FloodTinyDataset(csv_file = csv_file,label_csv = label_csv)

transformed_dataset = FloodTinyDataset(csv_file=csv_file, 
label_csv = label_csv, transform=transforms.Compose([transforms.Resize(2048),
transforms.RandomRotation(10),
transforms.RandomCrop(2000),
transforms.RandomHorizontalFlip(), 
transforms.ToTensor()]))

def show_images_batch(sample_batched):
    images_batch = sample_batched['image']
    batch_size = len(images_batch)
    im_size = images_batch.size(2)
    grid_border_size = 2

    grid = utils.make_grid(images_batch)
    plt.imshow(grid.numpy().transpose((1, 2, 0)))

    for i in range(batch_size):
        plt.title('Batch from dataloader')

#### Here, we split the Dataset into training and testing subsets ####

batch_size = 16
test_split_ratio = .2
shuffle_dataset = True
random_seed= 42

# Creating data indices for training and validation splits:
dataset_size = len(transformed_dataset)
indices = list(range(dataset_size))
split = int(np.floor(test_split_ratio * dataset_size))
if shuffle_dataset :
    np.random.seed(random_seed)
    np.random.shuffle(indices)
train_indices, test_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
test_sampler = SubsetRandomSampler(test_indices)

train_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,
                                           sampler=train_sampler)
test_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,
                                                sampler=test_sampler)

import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 497 * 497, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        ### Binary classification output layer size should be 2
        self.fc4 = nn.Linear(10, 2)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = self.fc4(x)
        return x


net = Net()

## Use this if images are stored in google Drive
from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/My\ Drive/

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import torch.optim as optim
import numpy as np
net = Net()

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)


for epoch in range(30):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):

        # get the inputs; data is a list of [inputs, labels]
        inputs = data['image']
        labels = data['damage:flood/water']
        # casting int to long for loss calculation#
        labels = labels.long()

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        #### 1600 images for training in total, batch size is 16
        #### So, it should be 100 batches
        if i % 5 == 4:    # print every 10 mini-batches
            print('[%d, %3d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 5))
            running_loss = 0.0
    state = {'epoch': epoch, 'state_dict': net.state_dict(),
             'optimizer_state_dict': optimizer.state_dict(), 'loss': loss}
    model_name = 'flood_tiny.pth'
    PATH = f"/content/drive/My Drive/{model_name}"
    torch.save(state, PATH)
print('Finished Training')

state = {'epoch': epoch, 'state_dict': net.state_dict(),
             'optimizer_state_dict': optimizer.state_dict(), 'loss': loss}

model_name = 'flood_tiny.pth'
'''Change PATH to where you want to put the trained model'''
PATH = f"/content/drive/My Drive/{model_name}"
torch.save(state, PATH)

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim

net = Net()
'''This is how to continue to train the model '''
model_name = 'flood_tiny.pth'
PATH = f"/content/drive/My Drive/{model_name}"
checkpoint = torch.load(PATH)
start_epoch = checkpoint['epoch']
net.load_state_dict(checkpoint['state_dict'])
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

for epoch in range(start_epoch+1, start_epoch+4):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):

        # get the inputs; data is a list of [inputs, labels]
        inputs = data['image']
        labels = data['damage:flood/water']
        # casting int to long for loss calculation#
        labels = labels.long()

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        #### 1600 images for training in total, batch size is 16
        #### So, it should be 100 batches
        if i % 5 == 4:    # print every 10 mini-batches
            print('[%d, %3d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 5))
            running_loss = 0.0
    state = {'epoch': epoch, 'state_dict': net.state_dict(),
             'optimizer_state_dict': optimizer.state_dict(), 'loss': loss}
    model_name = 'flood_tiny.pth'
    PATH = f"/content/drive/My Drive/{model_name}"
    torch.save(state, PATH)
print('Finished Training')

state = {'epoch': epoch, 'state_dict': net.state_dict(),
             'optimizer_state_dict': optimizer.state_dict(), 'loss': loss}

model_name = 'flood_tiny.pth'
PATH = f"/content/drive/My Drive/{model_name}"
torch.save(state, PATH)

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
PATH = '/content/drive/My Drive/flood_tiny.pth'
def imshow(img):
    #img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.figure(figsize=[16, 16])
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(test_loader)
#images, labels = dataiter.next()
images = dataiter.next()['image']
labels = dataiter.next()['damage:flood/water']

# print images
classes = (0, 1)
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join('%5s' % labels[j] for j in range(16)))

net = Net()

checkpoint = torch.load(PATH)

net.load_state_dict(checkpoint['state_dict'])

optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

outputs = net(images)
_, predicted = torch.max(outputs, 1)

print('Predicted: ', ' '.join('%5s' % predicted[j]
                              for j in range(16)))

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
net = Net()
model_name = 'flood_tiny.pth'
PATH = f"/content/drive/My Drive/{model_name}"
checkpoint = torch.load(PATH)
start_epoch = checkpoint['epoch']
net.load_state_dict(checkpoint['state_dict'])
correct = 0
total = 0
with torch.no_grad():
    for data in test_loader:
        images = data['image']
        labels = data['damage:flood/water']
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
#
print('Accuracy of the network on the 1600 test images: %d %%' % (
    100 * correct / total))

net = Net()
model_name = 'flood_tiny.pth'
PATH = f"/content/drive/My Drive/{model_name}"
checkpoint = torch.load(PATH)
start_epoch = checkpoint['epoch']
net.load_state_dict(checkpoint['state_dict'])
class_correct = list(0. for i in range(2))
class_total = list(0. for i in range(2))
with torch.no_grad():
    for data in test_loader:
        images = data['image']
        labels = data['damage:flood/water']
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(16):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1


for i in range(2):
    print('Accuracy of %5s : %2d %%' % (
        i, 100 * class_correct[i] / class_total[i]))